# .github/workflows/security.yml
# Umfassende Sicherheitsüberprüfungen

# ===== SECURITY AUDIT EXCEPTIONS =====
# Diese RUSTSEC Advisories werden bewusst ignoriert (siehe SECURITY.md & deny.toml):
# - RUSTSEC-2023-0071: RSA Marvin Attack - Betrifft nur Windows SSPI Auth, minimales Risiko
# - RUSTSEC-2021-0145: atty unaligned read - inquire dependency, kein sicherer Upgrade
# - RUSTSEC-2024-0375: atty unmaintained - inquire dependency, kein sicherer Upgrade  
# - RUSTSEC-2024-0436: paste crate - no longer maintained, aber keine Alternative verfügbar
# 
# Begründung RUSTSEC-2023-0071:
# - CVE Severity: Medium (CVSS 5.9), aber praktisches Risiko gering
# - Nur Windows-Builds mit SSPI betroffen (Linux/macOS nicht betroffen)  
# - Erfordert lokalen Angreifer mit präzisen Timing-Messungen
# - Mitigationen: Basic Auth verwenden, Netzwerk-Isolation, Monitoring
# - Dependency-Pfad: rsa v0.9.8 → picky v7.0.0-rc.14 → sspi v0.10.1
# 
# Begründung RUSTSEC-2021-0145 & RUSTSEC-2024-0375:
# - atty crate hat unaligned read issue und ist unmaintained
# - Verwendet durch inquire dependency (TUI input handling)
# - Keine sicheren Upgrade-Pfade verfügbar (inquire abhängig von atty)
# - Minimale Attack Surface - nur für CLI-Prompts verwendet
# 
# Begründung RUSTSEC-2024-0436:
# - paste v1.0.15 nicht mehr maintained seit 2024
# - Nur für proc-macro Helpers in ratatui verwendet (minimale Attack Surface)
# - Keine bekannten Security-Vulnerabilities, nur Maintenance-Status
# - Alternative: Warten auf ratatui Update oder eigene proc-macro Implementation
# - Monitoring: ratatui Issues für paste-Ersatz, proc-macro-Alternativen
# 
# Referenz: SECURITY.md, CVE-Tracking, Upstream sspi/picky/ratatui Updates
# ==========================================

name: Security Audit

on:
  schedule:
    - cron: '0 6 * * *'  # Täglich um 6:00 UTC
  push:
    branches: [ main ]
    paths: 
      - 'Cargo.toml'
      - 'Cargo.lock'
      - '.github/workflows/security.yml'
  workflow_dispatch:
    inputs:
      audit-level:
        description: 'Audit Level'
        required: true
        default: 'standard'
        type: choice
        options:
        - standard
        - comprehensive
        - minimal

permissions:
  contents: read
  security-events: write
  actions: read

env:
  CARGO_TERM_COLOR: always
  # Security audit exceptions (siehe Header-Kommentare und deny.toml)
  RUSTSEC_IGNORE_LIST: "RUSTSEC-2023-0071,RUSTSEC-2021-0145,RUSTSEC-2024-0375,RUSTSEC-2024-0436"
  # Audit level configuration
  AUDIT_LEVEL: ${{ github.event.inputs.audit-level || 'standard' }}

jobs:
  # ===== VULNERABILITY SCANNING =====
  vulnerability-scan:
    name: Vulnerability Scan
    runs-on: ubuntu-latest
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Install Rust
      uses: dtolnay/rust-toolchain@stable

    - name: Install security tools
      uses: taiki-e/install-action@v2
      with:
        tool: cargo-audit,cargo-deny,cargo-geiger

    # Multiple security tools for comprehensive coverage
    - name: Cargo Audit (RustSec)
      run: |
        set -euo pipefail
        echo "::group::Cargo Audit"
        echo "🔍 Security Audit with documented exceptions:"
        echo "   📋 Ignored Advisories (see SECURITY.md and deny.toml for full details):"
        echo "   - RUSTSEC-2023-0071: RSA Marvin Attack"
        echo "     • Severity: Medium (CVSS 5.9)"
        echo "     • Impact: Windows SSPI only, requires local timing attack"
        echo "     • Mitigation: Use Basic Auth, network isolation, monitoring"
        echo "   - RUSTSEC-2021-0145: atty unaligned read"
        echo "     • Impact: inquire dependency, no safe upgrade path"
        echo "   - RUSTSEC-2024-0375: atty unmaintained"
        echo "     • Impact: inquire dependency, no safe upgrade path"  
        echo "   - RUSTSEC-2024-0436: paste crate unmaintained"
        echo "     • Severity: Informational (maintenance warning)"
        echo "     • Impact: Minimal attack surface (proc-macro helper only)"
        echo "     • Status: No functional alternatives available"
        echo "     • Monitoring: ratatui updates for paste replacement"
        echo ""
        
        # Build audit arguments from RUSTSEC_IGNORE_LIST environment variable
        AUDIT_ARGS="--deny warnings"
        if [ -n "${RUSTSEC_IGNORE_LIST:-}" ]; then
          echo "📋 Using RUSTSEC_IGNORE_LIST: $RUSTSEC_IGNORE_LIST"
          # Convert comma-separated list to --ignore arguments
          for rustsec_id in $(echo "$RUSTSEC_IGNORE_LIST" | tr ',' ' '); do
            AUDIT_ARGS="$AUDIT_ARGS --ignore $rustsec_id"
          done
        fi
        echo "🔧 Audit command: cargo audit $AUDIT_ARGS"
        
        # Generate JSON report and validate in one step
        if cargo audit --json $AUDIT_ARGS > audit-report.json 2>/dev/null; then
          echo "✅ Audit completed successfully with documented exceptions"
        else
          AUDIT_EXIT_CODE=$?
          echo "⚠️ Audit found issues (exit code: $AUDIT_EXIT_CODE)"
          
          # Fallback: generate empty report and re-run for proper error display
          echo '{"vulnerabilities":[]}' > audit-report.json
          echo "Re-running audit for detailed error output:"
          cargo audit $AUDIT_ARGS || true
          
          # If not just known issues, fail the step
          if [ $AUDIT_EXIT_CODE -ne 0 ]; then
            echo "❌ Security audit failed with unexpected vulnerabilities"
            exit $AUDIT_EXIT_CODE
          fi
        fi
        echo "::endgroup::"

    - name: Cargo Deny (Licenses & Advisories)
      run: |
        set -euo pipefail
        echo "::group::Cargo Deny"
        
        # Generate JSON report (allows documented failures)
        if ! cargo deny --format=json check > deny-report.json 2>/dev/null; then
          echo "⚠️ Cargo deny found issues, generating fallback report..."
          echo '{"advisories":[],"licenses":[],"bans":[]}' > deny-report.json
        fi
        
        # Run actual checks (will fail on policy violations)
        echo "Running cargo deny checks..."
        cargo deny check advisories
        cargo deny check licenses
        cargo deny check bans
        echo "::endgroup::"

    - name: Cargo Geiger (Unsafe Code Analysis)
      run: |
        echo "::group::Unsafe Code Analysis"
        echo '{"packages":[]}' > geiger-report.json
        cargo geiger --forbid-only
        echo "::endgroup::"

    - name: Upload security reports
      # Only upload artifacts for manual workflow runs and scheduled runs (not every push)
      if: always() && (github.event_name == 'workflow_dispatch' || github.event_name == 'schedule')
      uses: actions/upload-artifact@v4
      with:
        name: security-reports-${{ github.run_id }}
        path: |
          audit-report.json
          deny-report.json
          geiger-report.json
        retention-days: 14

  # ===== EXCEPTION VALIDATION =====
  validate-exceptions:
    name: Validate Security Exceptions
    runs-on: ubuntu-latest
    needs: [vulnerability-scan]
    # Run weekly to check if ignored advisories are still relevant
    if: >
      github.event_name == 'schedule' ||
      (github.event_name == 'workflow_dispatch' && github.event.inputs.audit-level == 'comprehensive')
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Install Rust and tools
      uses: dtolnay/rust-toolchain@stable

    - name: Install security tools
      uses: taiki-e/install-action@v2
      with:
        tool: cargo-audit

    - name: Install jq for JSON processing
      run: sudo apt-get update && sudo apt-get install -y jq

    - name: Validate RUSTSEC exceptions
      run: |
        set -euo pipefail
        echo "::group::Exception Validation"
        echo "🔍 Validating RUSTSEC_IGNORE_LIST exceptions against current dependency state..."
        
        # Parse ignored advisories from environment
        if [ -z "${RUSTSEC_IGNORE_LIST:-}" ]; then
          echo "⚠️ No RUSTSEC_IGNORE_LIST found - validation skipped"
          echo "STALE_EXCEPTIONS=" >> $GITHUB_ENV
          echo "VALID_EXCEPTIONS=" >> $GITHUB_ENV
          exit 0
        fi
        
        echo "📋 Checking exceptions: $RUSTSEC_IGNORE_LIST"
        
        # Performance optimization: Single audit run to get all current vulnerabilities
        echo "🚀 Running comprehensive audit scan..."
        cargo audit --json --ignore-everything > full-audit.json 2>/dev/null || {
          echo '{"vulnerabilities":[]}' > full-audit.json
        }
        
        # Get currently affecting vulnerabilities (without any ignores)
        cargo audit --json > current-vulnerabilities.json 2>/dev/null || {
          echo '{"vulnerabilities":[]}' > current-vulnerabilities.json
        }
        
        echo "📊 Found $(jq '.vulnerabilities | length' full-audit.json) total advisories in database"
        echo "📊 Found $(jq '.vulnerabilities | length' current-vulnerabilities.json) affecting current dependencies"
        
        # Convert comma-separated list to array for safer processing
        readarray -t ADVISORY_ARRAY < <(echo "$RUSTSEC_IGNORE_LIST" | tr ',' '\n' | grep -v '^$')
        
        # Initialize result tracking
        declare -a STALE_EXCEPTIONS_ARRAY=()
        declare -a VALID_EXCEPTIONS_ARRAY=()
        
        # Create reports
        echo "# Security Exception Validation Report" > exception-validation.md
        echo "" >> exception-validation.md
        echo "**Generated:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> exception-validation.md
        echo "**Workflow:** [View Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> exception-validation.md
        echo "" >> exception-validation.md
        echo "## Executive Summary" >> exception-validation.md
        echo "" >> exception-validation.md
        echo "This automated validation checks if security exceptions in \`RUSTSEC_IGNORE_LIST\` are still necessary." >> exception-validation.md
        echo "" >> exception-validation.md
        
        # Create JSON report for machine processing
        echo '{"validation_date":"'$(date -u '+%Y-%m-%dT%H:%M:%SZ')'","exceptions":[]}' > exception-validation.json
        
        echo "## Advisory Validation Results" >> exception-validation.md
        echo "" >> exception-validation.md
        
        # Process each advisory
        for rustsec_id in "${ADVISORY_ARRAY[@]}"; do
          echo "Validating $rustsec_id..."
          
          # Check if this advisory affects current dependencies
          AFFECTS_CURRENT=$(jq -r --arg id "$rustsec_id" '
            .vulnerabilities[] | 
            select(.advisory.id == $id) | 
            .advisory.id' current-vulnerabilities.json)
          
          # Get advisory details from full database
          ADVISORY_EXISTS=$(jq -r --arg id "$rustsec_id" '
            .vulnerabilities[] | 
            select(.advisory.id == $id) | 
            .advisory.id' full-audit.json)
          
          # Determine status
          if [ -n "$AFFECTS_CURRENT" ]; then
            echo "✅ $rustsec_id: Still affects current dependencies (exception valid)"
            VALID_EXCEPTIONS_ARRAY+=("$rustsec_id")
            STATUS="valid"
            REASON="Still affecting current dependency versions"
            echo "- ✅ **$rustsec_id**: Active threat - exception remains necessary" >> exception-validation.md
          elif [ -n "$ADVISORY_EXISTS" ]; then
            echo "⚠️ $rustsec_id: Advisory exists but doesn't affect current versions (potentially stale)"
            STALE_EXCEPTIONS_ARRAY+=("$rustsec_id")
            STATUS="potentially_stale" 
            REASON="Advisory exists but current dependency versions are not affected"
            echo "- ⚠️ **$rustsec_id**: Potentially outdated - dependencies may have been updated" >> exception-validation.md
          else
            echo "❌ $rustsec_id: Advisory not found in database (likely stale)"
            STALE_EXCEPTIONS_ARRAY+=("$rustsec_id")
            STATUS="stale"
            REASON="Advisory not found in current RustSec database"
            echo "- ❌ **$rustsec_id**: Advisory not found - may have been withdrawn" >> exception-validation.md
          fi
          
          # Add to JSON report
          jq --arg id "$rustsec_id" --arg status "$STATUS" --arg reason "$REASON" \
            '.exceptions += [{"advisory_id": $id, "status": $status, "reason": $reason}]' \
            exception-validation.json > temp.json && mv temp.json exception-validation.json
        done
        
        # Generate summary section
        echo "" >> exception-validation.md
        echo "## Summary" >> exception-validation.md
        echo "" >> exception-validation.md
        echo "| Status | Count | Action Required |" >> exception-validation.md
        echo "|--------|-------|-----------------|" >> exception-validation.md
        echo "| ✅ Valid | ${#VALID_EXCEPTIONS_ARRAY[@]} | None - exceptions remain necessary |" >> exception-validation.md
        echo "| ⚠️ Potentially Stale | ${#STALE_EXCEPTIONS_ARRAY[@]} | Review and consider removal |" >> exception-validation.md
        
        # Add recommendations
        echo "" >> exception-validation.md
        echo "## 🔧 Recommendations" >> exception-validation.md
        echo "" >> exception-validation.md
        
        if [ ${#STALE_EXCEPTIONS_ARRAY[@]} -gt 0 ]; then
          echo "### Stale Exception Cleanup" >> exception-validation.md
          echo "" >> exception-validation.md
          echo "The following exceptions should be reviewed for removal:" >> exception-validation.md
          echo "" >> exception-validation.md
          
          for stale_id in "${STALE_EXCEPTIONS_ARRAY[@]}"; do
            echo "1. **$stale_id**" >> exception-validation.md
            echo "   - Remove from \`RUSTSEC_IGNORE_LIST\` in \`.github/workflows/security.yml\`" >> exception-validation.md
            echo "   - Update documentation in \`SECURITY.md\`" >> exception-validation.md
            echo "   - Test: \`cargo audit\` (should pass without new vulnerabilities)" >> exception-validation.md
            echo "" >> exception-validation.md
          done
          
          echo "### Automated Cleanup Command" >> exception-validation.md
          echo "" >> exception-validation.md
          echo "\`\`\`bash" >> exception-validation.md
          echo "# Remove stale exceptions (review first!)" >> exception-validation.md
          
          # Build new ignore list without stale exceptions
          CLEANED_LIST=""
          for valid_id in "${VALID_EXCEPTIONS_ARRAY[@]}"; do
            if [ -n "$CLEANED_LIST" ]; then
              CLEANED_LIST="$CLEANED_LIST,$valid_id"
            else
              CLEANED_LIST="$valid_id"
            fi
          done
          
          echo "# New RUSTSEC_IGNORE_LIST: \"$CLEANED_LIST\"" >> exception-validation.md
          echo "\`\`\`" >> exception-validation.md
        else
          echo "✅ All exceptions are still valid and necessary." >> exception-validation.md
          echo "" >> exception-validation.md
          echo "No action required at this time." >> exception-validation.md
        fi
        
        echo "" >> exception-validation.md
        echo "---" >> exception-validation.md
        echo "*This report is generated weekly via automated GitHub Actions workflow.*" >> exception-validation.md
        
        # Set environment variables for subsequent steps
        STALE_LIST=$(IFS=','; echo "${STALE_EXCEPTIONS_ARRAY[*]}")
        VALID_LIST=$(IFS=','; echo "${VALID_EXCEPTIONS_ARRAY[*]}")
        
        echo "STALE_EXCEPTIONS=$STALE_LIST" >> $GITHUB_ENV
        echo "VALID_EXCEPTIONS=$VALID_LIST" >> $GITHUB_ENV
        echo "STALE_COUNT=${#STALE_EXCEPTIONS_ARRAY[@]}" >> $GITHUB_ENV
        echo "VALID_COUNT=${#VALID_EXCEPTIONS_ARRAY[@]}" >> $GITHUB_ENV
        
        # GitHub Step Summary
        echo "## 🔒 Security Exception Validation" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Date:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
        echo "**Total Exceptions:** ${#ADVISORY_ARRAY[@]}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Status | Count | Advisories |" >> $GITHUB_STEP_SUMMARY
        echo "|--------|-------|------------|" >> $GITHUB_STEP_SUMMARY
        echo "| ✅ Valid | ${#VALID_EXCEPTIONS_ARRAY[@]} | $VALID_LIST |" >> $GITHUB_STEP_SUMMARY
        echo "| ⚠️ Stale | ${#STALE_EXCEPTIONS_ARRAY[@]} | $STALE_LIST |" >> $GITHUB_STEP_SUMMARY
        
        if [ ${#STALE_EXCEPTIONS_ARRAY[@]} -gt 0 ]; then
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "::warning title=Stale Security Exceptions::Found ${#STALE_EXCEPTIONS_ARRAY[@]} potentially outdated exceptions: $STALE_LIST"
        else
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "::notice title=All Exceptions Valid::All security exceptions are still necessary"
        fi
        
        # Output results
        echo "::endgroup::"
        echo ""
        echo "📊 Validation Results:"
        echo "   Valid exceptions: ${#VALID_EXCEPTIONS_ARRAY[@]}"
        echo "   Stale exceptions: ${#STALE_EXCEPTIONS_ARRAY[@]}"
        if [ ${#STALE_EXCEPTIONS_ARRAY[@]} -gt 0 ]; then
          echo "   Stale advisories: $STALE_LIST"
        fi

    - name: Upload validation reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: exception-validation-${{ github.run_id }}
        path: |
          exception-validation.md
          exception-validation.json
          full-audit.json
          current-vulnerabilities.json
        retention-days: 30

    - name: Create issue for stale exceptions
      if: env.STALE_COUNT != '0'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('exception-validation.md', 'utf8');
          const today = new Date().toISOString().split('T')[0];
          
          const title = `Security Exception Review Required - ${today}`;
          const body = `
          ## 🔄 Security Exception Validation Alert
          
          **Date:** ${new Date().toISOString()}  
          **Trigger:** Weekly automated validation  
          **Stale Exceptions Found:** ${{ env.STALE_COUNT }}  
          **Stale Advisories:** ${{ env.STALE_EXCEPTIONS }}
          
          ### 📋 Full Validation Report
          
          ${report}
          
          ### 🔧 Action Items
          
          1. **Review each stale exception** listed above
          2. **Test removal** by updating \`RUSTSEC_IGNORE_LIST\` in \`.github/workflows/security.yml\`
          3. **Update documentation** in \`SECURITY.md\` 
          4. **Verify no new vulnerabilities** with \`cargo audit\`
          5. **Close this issue** once cleanup is complete
          
          ### 🤖 Automation Details
          
          - **Frequency:** Weekly (every Sunday)
          - **Trigger:** GitHub Actions schedule + manual dispatch
          - **Workflow:** [View Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
          - **Reports:** Check workflow artifacts for detailed JSON reports
          `;
          
          // Better duplicate prevention: check for issues with exact title pattern from today
          const issues = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            labels: ['security', 'stale-exceptions'],
            state: 'open'
          });
          
          // Check if issue for today already exists
          const todayIssueExists = issues.data.some(issue => 
            issue.title.includes('Security Exception Review Required') && 
            issue.title.includes(today)
          );
          
          if (!todayIssueExists) {
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: body,
              labels: ['security', 'stale-exceptions', 'maintenance', 'automated'],
              assignees: [] // Could add default assignees here
            });
            console.log(`Created issue for ${${{ env.STALE_COUNT }}} stale security exceptions`);
          } else {
            console.log('Issue for today already exists, skipping creation');
          }

  # ===== DEPENDENCY ANALYSIS =====
  dependency-analysis:
    name: Dependency Analysis
    runs-on: ubuntu-latest
    # Only run expensive dependency analysis on schedule/dispatch (not every push)
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Install Rust stable and nightly
      uses: dtolnay/rust-toolchain@stable

    - name: Install nightly for udeps
      uses: dtolnay/rust-toolchain@nightly

    - name: Install analysis tools
      uses: taiki-e/install-action@v2
      with:
        tool: cargo-machete,cargo-udeps,cargo-outdated

    - name: Analyze dependencies
      run: |
        echo "::group::Unused Dependencies (machete)"
        cargo machete --with-metadata > machete-report.txt || true
        cat machete-report.txt
        echo "::endgroup::"
        
        echo "::group::Unused Dependencies (udeps)"
        cargo +nightly udeps --all-targets > udeps-report.txt || true
        cat udeps-report.txt
        echo "::endgroup::"
        
        echo "::group::Outdated Dependencies"
        cargo outdated --format json > outdated-report.json || true
        cargo outdated
        echo "::endgroup::"

    - name: Check for bloated dependencies
      run: |
        echo "::group::Dependency Size Analysis"
        cargo tree --duplicates
        cargo tree --format "{p} {f}" | grep -E "(build|dev)" | sort | uniq -c | sort -nr
        echo "::endgroup::"

    - name: Upload dependency reports
      # Only upload artifacts for manual workflow runs and scheduled runs (not every push)
      if: always() && (github.event_name == 'workflow_dispatch' || github.event_name == 'schedule')
      uses: actions/upload-artifact@v4
      with:
        name: dependency-reports-${{ github.run_id }}
        path: |
          machete-report.txt
          udeps-report.txt
          outdated-report.json
        retention-days: 7

  # ===== SUPPLY CHAIN SECURITY =====
  supply-chain:
    name: Supply Chain Security
    runs-on: ubuntu-latest
    # Only run expensive supply chain analysis on schedule/dispatch (not every push)
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    env:
      ENABLE_CREV: false  # Opt-in for crev to avoid unnecessary signatures
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Install Rust
      uses: dtolnay/rust-toolchain@stable

    - name: Install supply chain tools
      uses: taiki-e/install-action@v2
      with:
        tool: cargo-vet,cargo-crev

    # Verify dependencies using cargo-vet
    - name: Verify dependencies
      run: |
        if [ -f "supply-chain/config.toml" ]; then
          echo "::group::Cargo Vet"
          echo "📋 Cargo-vet configuration found, running supply chain verification..."
          
          # Generate JSON report for SARIF (allow policy failures)
          if ! cargo vet --format json > vet-report.json 2>/dev/null; then
            echo "⚠️ Vet found unaudited dependencies, check required"
            echo '{"conclusion":"failure","violations":[]}' > vet-report.json
          fi
          
          # Run actual verification (strict mode - can fail the build)
          if [ "${{ env.AUDIT_LEVEL }}" = "comprehensive" ]; then
            echo "🔒 Comprehensive mode: enforcing supply chain verification"
            cargo vet
          else
            echo "📝 Standard mode: logging supply chain status only"
            cargo vet || echo "⚠️ Supply chain verification incomplete (non-blocking in standard mode)"
          fi
          echo "::endgroup::"
        else
          echo "📝 No cargo-vet configuration found (supply-chain/config.toml missing)"
          echo "💡 Consider initializing: cargo vet init"
          echo '{"conclusion":"skipped","violations":[]}' > vet-report.json
        fi

    # Check crate reviews using cargo-crev (optional)
    - name: Check crate reviews
      if: env.ENABLE_CREV == 'true'
      run: |
        echo "::group::Cargo Crev"
        echo "🔍 Fetching community crate reviews..."
        
        # Initialize crev if needed
        if ! cargo crev id current >/dev/null 2>&1; then
          echo "📝 No crev identity found, creating anonymous review session..."
          cargo crev id gen --url "https://github.com/${{ github.repository }}" --github-username "${{ github.actor }}" || true
        fi
        
        # Fetch latest reviews (non-blocking)
        cargo crev repo fetch all || echo "⚠️ Could not fetch latest crev data"
        
        # Generate review report
        if cargo crev verify --for-id $(cargo crev id current 2>/dev/null || echo "anonymous") > crev-report.txt 2>/dev/null; then
          echo "✅ Crev verification completed"
          head -50 crev-report.txt
        else
          echo "⚠️ Crev verification incomplete or failed"
          echo "No community reviews available" > crev-report.txt
        fi
        echo "::endgroup::"
    
    # Create placeholder crev report if disabled
    - name: Create placeholder crev report
      if: env.ENABLE_CREV != 'true'
      run: |
        echo "📝 CREV disabled (ENABLE_CREV != true), creating placeholder report"
        echo "CREV verification skipped - enable via ENABLE_CREV=true" > crev-report.txt

    - name: Upload supply chain reports
      # Only upload artifacts for manual workflow runs and scheduled runs (not every push)
      if: always() && (github.event_name == 'workflow_dispatch' || github.event_name == 'schedule')
      uses: actions/upload-artifact@v4
      with:
        name: supply-chain-reports-${{ github.run_id }}
        path: |
          vet-report.json
          crev-report.txt
        retention-days: 7

  # ===== SARIF SECURITY REPORT =====
  sarif-report:
    name: SARIF Security Report
    runs-on: ubuntu-latest
    needs: [vulnerability-scan]
    # Only generate SARIF when artifacts are available (schedule/dispatch) or always run but handle missing artifacts
    if: always()
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Install jq for JSON processing
      run: sudo apt-get update && sudo apt-get install -y jq

    - name: Download security reports
      # Only download if artifacts were uploaded (schedule/dispatch)
      if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
      uses: actions/download-artifact@v4
      with:
        name: security-reports-${{ github.run_id }}
        path: security-reports/

    - name: Create fallback security reports for push events
      # For push events, create empty reports so SARIF conversion doesn't fail
      if: github.event_name == 'push'
      run: |
        mkdir -p security-reports
        echo '{"vulnerabilities":[]}' > security-reports/audit-report.json
        echo '{"advisories":[],"licenses":[],"bans":[]}' > security-reports/deny-report.json
        echo '{"packages":[]}' > security-reports/geiger-report.json

    # Download dependency reports if available (only exists for schedule/dispatch)
    - name: Download dependency reports
      if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
      continue-on-error: true
      uses: actions/download-artifact@v4
      with:
        name: dependency-reports-${{ github.run_id }}
        path: dependency-reports/

    # GitHub Advisory Database integration
    - name: GitHub Advisory Database Check
      run: |
        echo "::group::GitHub Advisory Database"
        echo "🔍 Cross-referencing with GitHub Advisory Database..."
        
        # Use GitHub CLI to check for advisories affecting our dependencies
        if command -v gh >/dev/null 2>&1; then
          # Extract package names from Cargo.lock for advisory lookup
          if [ -f "Cargo.lock" ]; then
            echo "📋 Checking dependencies against GitHub Advisory Database..."
            
            # Simple advisory check (this could be enhanced with proper API calls)
            gh api graphql -f query='
            query($first: Int!) {
              securityAdvisories(first: $first, ecosystem: RUST) {
                nodes {
                  summary
                  severity
                  publishedAt
                  vulnerabilities(first: 10) {
                    nodes {
                      package { name }
                      vulnerableVersionRange
                    }
                  }
                }
              }
            }' -F first=50 > github-advisories.json || echo '{"data":{"securityAdvisories":{"nodes":[]}}}' > github-advisories.json
            
            echo "✅ GitHub Advisory Database check completed"
          else
            echo "⚠️ No Cargo.lock found for advisory cross-reference"
            echo '{"data":{"securityAdvisories":{"nodes":[]}}}' > github-advisories.json
          fi
        else
          echo "⚠️ GitHub CLI not available, skipping advisory database integration"
          echo '{"data":{"securityAdvisories":{"nodes":[]}}}' > github-advisories.json
        fi
        echo "::endgroup::"

    # Convert reports to SARIF format for GitHub Security tab
    - name: Convert to SARIF
      run: |
        # Get dynamic tool versions
        AUDIT_VERSION=$(cargo audit --version 2>/dev/null | grep -o '[0-9]\+\.[0-9]\+\.[0-9]\+' | head -1 || echo "0.21.0")
        DENY_VERSION=$(cargo deny --version 2>/dev/null | grep -o '[0-9]\+\.[0-9]\+\.[0-9]\+' | head -1 || echo "0.16.0")
        GEIGER_VERSION=$(cargo geiger --version 2>/dev/null | grep -o '[0-9]\+\.[0-9]\+\.[0-9]\+' | head -1 || echo "0.11.7")
        
        python3 << 'EOF'
        import json
        import os
        import sys
        import re
        from datetime import datetime
        
        def create_sarif_base():
            return {
                "$schema": "https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json",
                "version": "2.1.0",
                "runs": []
            }
        
        def load_json_file(filepath, default=None):
            try:
                with open(filepath, 'r') as f:
                    return json.load(f)
            except (FileNotFoundError, json.JSONDecodeError) as e:
                print(f"Warning: Could not load {filepath}: {e}", file=sys.stderr)
                return default or {}
        
        def load_text_file(filepath, default=""):
            try:
                with open(filepath, 'r') as f:
                    return f.read()
            except (FileNotFoundError) as e:
                print(f"Warning: Could not load {filepath}: {e}", file=sys.stderr)
                return default
        
        def convert_audit_to_sarif():
            audit_data = load_json_file('security-reports/audit-report.json', {'vulnerabilities': []})
            
            rules = {}
            results = []
            
            for vuln in audit_data.get('vulnerabilities', []):
                advisory = vuln.get('advisory', {})
                rustsec_id = advisory.get('id', 'UNKNOWN')
                title = advisory.get('title', 'Unknown vulnerability')
                description = advisory.get('description', 'No description available')
                severity = advisory.get('cvss', {}).get('severity', 'medium').lower()
                
                # Map severity to SARIF levels
                level_map = {
                    'critical': 'error',
                    'high': 'error', 
                    'medium': 'warning',
                    'low': 'note',
                    'informational': 'note'
                }
                level = level_map.get(severity, 'warning')
                
                # Create rule
                rules[rustsec_id] = {
                    "id": rustsec_id,
                    "name": f"Security/{rustsec_id}",
                    "shortDescription": {"text": title},
                    "fullDescription": {"text": description},
                    "helpUri": f"https://rustsec.org/advisories/{rustsec_id}",
                    "properties": {
                        "tags": ["security", "vulnerability"],
                        "precision": "very-high"
                    }
                }
                
                # Create result for affected package
                affected_packages = vuln.get('package', {})
                package_name = affected_packages.get('name', 'unknown')
                package_version = affected_packages.get('version', 'unknown')
                
                # Determine better artifact location
                artifact_uri = "Cargo.lock"
                if package_name in ['dnspx']:
                    artifact_uri = "Cargo.toml"
                elif package_name.startswith('dnspx-'):
                    artifact_uri = f"crates/{package_name}/Cargo.toml"
                else:
                    artifact_uri = f"dependencies/{package_name}/Cargo.toml"
                
                results.append({
                    "ruleId": rustsec_id,
                    "level": level,
                    "message": {
                        "text": f"Vulnerability {rustsec_id} in {package_name} v{package_version}: {title}"
                    },
                    "locations": [{
                        "physicalLocation": {
                            "artifactLocation": {"uri": artifact_uri},
                            "region": {"startLine": 1}
                        }
                    }],
                    "partialFingerprints": {
                        "package-version": f"{package_name}@{package_version}",
                        "advisory-id": rustsec_id,
                        "cvss-severity": severity,
                        "vulnerability-type": "rustsec-advisory"
                    }
                })
            
            return {
                "tool": {
                    "driver": {
                        "name": "cargo-audit",
                        "version": os.environ.get('AUDIT_VERSION', '0.21.0'),
                        "informationUri": "https://github.com/RustSec/rustsec/tree/main/cargo-audit",
                        "rules": list(rules.values())
                    }
                },
                "results": results
            }
        
        def convert_deny_to_sarif():
            deny_data = load_json_file('security-reports/deny-report.json', {'advisories': [], 'licenses': [], 'bans': []})
            
            rules = {}
            results = []
            
            # Process advisories
            for advisory in deny_data.get('advisories', []):
                adv_id = advisory.get('advisory', {}).get('id', 'UNKNOWN')
                title = advisory.get('advisory', {}).get('title', 'Unknown advisory')
                description = advisory.get('advisory', {}).get('description', 'No description')
                
                rules[f"deny-advisory-{adv_id}"] = {
                    "id": f"deny-advisory-{adv_id}",
                    "name": f"Deny/Advisory/{adv_id}",
                    "shortDescription": {"text": title},
                    "fullDescription": {"text": description},
                    "helpUri": f"https://rustsec.org/advisories/{adv_id}",
                    "properties": {
                        "tags": ["security", "advisory"],
                        "precision": "very-high"
                    }
                }
                
                results.append({
                    "ruleId": f"deny-advisory-{adv_id}",
                    "level": "error",
                    "message": {"text": f"Advisory {adv_id}: {title}"},
                    "locations": [{
                        "physicalLocation": {
                            "artifactLocation": {"uri": "Cargo.lock"},
                            "region": {"startLine": 1}
                        }
                    }],
                    "partialFingerprints": {
                        "advisory-id": adv_id
                    }
                })
            
            # Process license violations
            for license_issue in deny_data.get('licenses', []):
                license_name = license_issue.get('license', 'Unknown')
                package_name = license_issue.get('package', {}).get('name', 'unknown')
                rule_id = f"deny-license-{license_name.replace(' ', '-').lower()}"
                
                rules[rule_id] = {
                    "id": rule_id,
                    "name": f"Deny/License/{license_name}",
                    "shortDescription": {"text": f"Disallowed license: {license_name}"},
                    "fullDescription": {"text": f"Package uses disallowed license: {license_name}"},
                    "properties": {
                        "tags": ["license", "compliance"],
                        "precision": "very-high"
                    }
                }
                
                # Better artifact location for license violations
                artifact_uri = "Cargo.toml"
                if package_name and package_name != 'unknown':
                    if package_name in ['dnspx']:
                        artifact_uri = "Cargo.toml"
                    else:
                        artifact_uri = f"dependencies/{package_name}/Cargo.toml"
                
                results.append({
                    "ruleId": rule_id,
                    "level": "warning",
                    "message": {"text": f"Package '{package_name}' uses disallowed license: {license_name}"},
                    "locations": [{
                        "physicalLocation": {
                            "artifactLocation": {"uri": artifact_uri},
                            "region": {"startLine": 1}
                        }
                    }],
                    "partialFingerprints": {
                        "package-license": f"{package_name}@{license_name}"
                    }
                })
            
            # Process banned dependencies
            for ban in deny_data.get('bans', []):
                crate_name = ban.get('crate', 'unknown')
                rule_id = f"deny-ban-{crate_name}"
                
                rules[rule_id] = {
                    "id": rule_id,
                    "name": f"Deny/Ban/{crate_name}",
                    "shortDescription": {"text": f"Banned dependency: {crate_name}"},
                    "fullDescription": {"text": f"Dependency {crate_name} is explicitly banned"},
                    "properties": {
                        "tags": ["dependency", "ban"],
                        "precision": "very-high"
                    }
                }
                
                # Better artifact location for banned dependencies
                artifact_uri = "Cargo.toml"
                if crate_name and crate_name != 'unknown':
                    if crate_name.startswith('dnspx'):
                        artifact_uri = "Cargo.toml"
                    else:
                        artifact_uri = f"dependencies/{crate_name}/Cargo.toml"
                
                results.append({
                    "ruleId": rule_id,
                    "level": "error",
                    "message": {"text": f"Banned dependency '{crate_name}' detected"},
                    "locations": [{
                        "physicalLocation": {
                            "artifactLocation": {"uri": artifact_uri},
                            "region": {"startLine": 1}
                        }
                    }],
                    "partialFingerprints": {
                        "banned-crate": crate_name
                    }
                })
            
            return {
                "tool": {
                    "driver": {
                        "name": "cargo-deny",
                        "version": os.environ.get('DENY_VERSION', '0.16.0'),
                        "informationUri": "https://github.com/EmbarkStudios/cargo-deny",
                        "rules": list(rules.values())
                    }
                },
                "results": results
            }
        
        def convert_geiger_to_sarif():
            geiger_data = load_json_file('security-reports/geiger-report.json', {'packages': []})
            
            rules = {
                "unsafe-code-detected": {
                    "id": "unsafe-code-detected",
                    "name": "UnsafeCode/Detection",
                    "shortDescription": {"text": "Unsafe code block detected"},
                    "fullDescription": {"text": "This crate contains unsafe code blocks that require manual review"},
                    "helpUri": "https://doc.rust-lang.org/book/ch19-01-unsafe-rust.html",
                    "properties": {
                        "tags": ["unsafe", "code-quality"],
                        "precision": "high"
                    }
                },
                "unsafe-code-forbidden": {
                    "id": "unsafe-code-forbidden",
                    "name": "UnsafeCode/Forbidden",
                    "shortDescription": {"text": "Forbidden unsafe code detected"},
                    "fullDescription": {"text": "This crate contains unsafe code that violates the forbid-unsafe policy"},
                    "helpUri": "https://github.com/geiger-rs/cargo-geiger#forbid-unsafe",
                    "properties": {
                        "tags": ["unsafe", "policy-violation"],
                        "precision": "high"
                    }
                }
            }
            
            results = []
            
            for package in geiger_data.get('packages', []):
                crate_name = package.get('name', 'unknown')
                version = package.get('version', '0.0.0')
                unsafe_count = package.get('unsafe_count', 0)
                unsafe_forbidden = package.get('unsafe_forbidden', False)
                
                # Determine artifact location based on crate name
                if crate_name in ['dnspx']:
                    artifact_uri = "src/lib.rs"
                elif crate_name.startswith('dnspx-'):
                    artifact_uri = f"src/{crate_name.replace('dnspx-', '')}/lib.rs"
                else:
                    artifact_uri = f"dependencies/{crate_name}/src/lib.rs"
                
                if unsafe_count > 0:
                    level = "error" if unsafe_forbidden else "note"
                    rule_id = "unsafe-code-forbidden" if unsafe_forbidden else "unsafe-code-detected"
                    
                    results.append({
                        "ruleId": rule_id,
                        "level": level,
                        "message": {
                            "text": f"Package '{crate_name}' v{version} contains {unsafe_count} unsafe blocks"
                        },
                        "locations": [{
                            "physicalLocation": {
                                "artifactLocation": {"uri": artifact_uri},
                                "region": {"startLine": 1}
                            }
                        }],
                        "partialFingerprints": {
                            "package-version": f"{crate_name}@{version}",
                            "unsafe-count": str(unsafe_count)
                        }
                    })
            
            return {
                "tool": {
                    "driver": {
                        "name": "cargo-geiger",
                        "version": os.environ.get('GEIGER_VERSION', '0.11.7'),
                        "informationUri": "https://github.com/geiger-rs/cargo-geiger",
                        "rules": list(rules.values())
                    }
                },
                "results": results
            }
        
        def convert_dependency_analysis_to_sarif():
            """Convert machete, udeps, and outdated reports to SARIF"""
            rules = {}
            results = []
            
            # Define rules
            rules["outdated-dependency"] = {
                "id": "outdated-dependency",
                "name": "Dependencies/Outdated",
                "shortDescription": {"text": "Outdated dependency detected"},
                "fullDescription": {"text": "A dependency has a newer version available"},
                "helpUri": "https://doc.rust-lang.org/cargo/commands/cargo-update.html",
                "properties": {
                    "tags": ["dependency", "maintenance"],
                    "precision": "low"
                }
            }
            
            rules["unused-dependency-machete"] = {
                "id": "unused-dependency-machete",
                "name": "Dependencies/UnusedMachete",
                "shortDescription": {"text": "Unused dependency detected by cargo-machete"},
                "fullDescription": {"text": "A dependency is declared but not used in the code (detected by cargo-machete)"},
                "helpUri": "https://github.com/bnjbvr/cargo-machete",
                "properties": {
                    "tags": ["dependency", "unused", "machete"],
                    "precision": "medium"
                }
            }
            
            rules["unused-dependency-udeps"] = {
                "id": "unused-dependency-udeps",
                "name": "Dependencies/UnusedUdeps", 
                "shortDescription": {"text": "Unused dependency detected by cargo-udeps"},
                "fullDescription": {"text": "A dependency is declared but not used in the code (detected by cargo-udeps)"},
                "helpUri": "https://github.com/est31/cargo-udeps",
                "properties": {
                    "tags": ["dependency", "unused", "udeps"],
                    "precision": "medium"
                }
            }
            
            # Process outdated dependencies
            outdated_data = load_json_file('dependency-reports/outdated-report.json', {'dependencies': []})
            
            for dep in outdated_data.get('dependencies', []):
                crate_name = dep.get('name', 'unknown')
                current = dep.get('project', 'unknown')
                latest = dep.get('latest', 'unknown')
                
                # Determine more specific artifact location
                artifact_uri = "Cargo.toml"
                if dep.get('kind') == 'dev':
                    artifact_uri = "Cargo.toml#dev-dependencies"
                elif dep.get('kind') == 'build':
                    artifact_uri = "Cargo.toml#build-dependencies"
                
                results.append({
                    "ruleId": "outdated-dependency",
                    "level": "note",
                    "message": {"text": f"Dependency {crate_name} can be updated from {current} to {latest}"},
                    "locations": [{
                        "physicalLocation": {
                            "artifactLocation": {"uri": artifact_uri},
                            "region": {"startLine": 1}
                        }
                    }],
                    "partialFingerprints": {
                        "dependency-name": crate_name,
                        "current-version": current
                    }
                })
            
            # Process machete unused dependencies (from text parsing)
            machete_text = load_text_file('dependency-reports/machete-report.txt')
            for line in machete_text.split('\n'):
                # Match lines like 'unused dependency: crate "foo" (lib)'
                match = re.search(r'unused dependency.*?\"([^\"]+)\"', line)
                if match:
                    crate_name = match.group(1)
                    context = line.strip()
                    
                    # Determine artifact based on dependency type
                    artifact_uri = "Cargo.toml"
                    if 'dev' in context.lower():
                        artifact_uri = "Cargo.toml#dev-dependencies"
                    elif 'build' in context.lower():
                        artifact_uri = "Cargo.toml#build-dependencies"
                    
                    results.append({
                        "ruleId": "unused-dependency-machete",
                        "level": "note",
                        "message": {"text": f"Unused dependency '{crate_name}' detected by cargo-machete: {context}"},
                        "locations": [{
                            "physicalLocation": {
                                "artifactLocation": {"uri": artifact_uri},
                                "region": {"startLine": 1}
                            }
                        }],
                        "partialFingerprints": {
                            "dependency-name": crate_name,
                            "tool": "machete"
                        }
                    })
            
            # Process udeps unused dependencies (from text parsing)
            udeps_text = load_text_file('dependency-reports/udeps-report.txt')
            for line in udeps_text.split('\n'):
                # Match lines with 'unused' dependencies
                if 'unused' in line.lower() and ('dependency' in line or 'crate' in line):
                    # Extract crate name from various formats
                    match = re.search(r'\"([^\"]+)\"', line)
                    if match:
                        crate_name = match.group(1)
                        context = line.strip()
                        
                        # Determine artifact based on dependency type
                        artifact_uri = "Cargo.toml"
                        if 'dev' in context.lower():
                            artifact_uri = "Cargo.toml#dev-dependencies"
                        elif 'build' in context.lower():
                            artifact_uri = "Cargo.toml#build-dependencies"
                        
                        results.append({
                            "ruleId": "unused-dependency-udeps",
                            "level": "note",
                            "message": {"text": f"Unused dependency '{crate_name}' detected by cargo-udeps: {context}"},
                            "locations": [{
                                "physicalLocation": {
                                    "artifactLocation": {"uri": artifact_uri},
                                    "region": {"startLine": 1}
                                }
                            }],
                            "partialFingerprints": {
                                "dependency-name": crate_name,
                                "tool": "udeps"
                            }
                        })
            
            # Get dynamic tool versions for proper attribution
            try:
                import subprocess
                outdated_version = subprocess.check_output(['cargo', 'outdated', '--version'], text=True).strip().split()[-1]
            except:
                outdated_version = "unknown"
            
            return {
                "tool": {
                    "driver": {
                        "name": "dnspx-dependency-analyzer",
                        "version": f"cargo-outdated-{outdated_version}",
                        "informationUri": "https://github.com/dnspx/dnspx",
                        "rules": list(rules.values())
                    }
                },
                "results": results
            }
        
        # Create comprehensive SARIF report
        sarif = create_sarif_base()
        
        # Add all tool runs
        audit_run = convert_audit_to_sarif()
        if audit_run['results'] or audit_run['tool']['driver']['rules']:
            sarif['runs'].append(audit_run)
        
        deny_run = convert_deny_to_sarif()
        if deny_run['results'] or deny_run['tool']['driver']['rules']:
            sarif['runs'].append(deny_run)
        
        geiger_run = convert_geiger_to_sarif()
        if geiger_run['results'] or geiger_run['tool']['driver']['rules']:
            sarif['runs'].append(geiger_run)
        
        # Add dependency analysis if reports exist
        if os.path.exists('dependency-reports'):
            dep_run = convert_dependency_analysis_to_sarif()
            if dep_run['results'] or dep_run['tool']['driver']['rules']:
                sarif['runs'].append(dep_run)
        
        # Ensure we have at least one run (even if empty) for valid SARIF
        if not sarif['runs']:
            sarif['runs'].append({
                "tool": {
                    "driver": {
                        "name": "security-scanner",
                        "version": "1.0.0",
                        "informationUri": "https://github.com/dnspx/dnspx",
                        "rules": []
                    }
                },
                "results": []
            })
        
        # Write SARIF file
        with open('security-results.sarif', 'w') as f:
            json.dump(sarif, f, indent=2)
        
        print(f"Generated comprehensive SARIF report with {len(sarif['runs'])} tool runs")
        print("\\n🔒 SARIF Security Report Summary:")
        print("=" * 50)
        
        total_rules = 0
        total_results = 0
        
        for i, run in enumerate(sarif['runs']):
            tool_name = run['tool']['driver']['name']
            rule_count = len(run['tool']['driver'].get('rules', []))
            result_count = len(run.get('results', []))
            total_rules += rule_count
            total_results += result_count
            
            print(f"  📊 Run {i+1}: {tool_name}")
            print(f"      Rules: {rule_count}, Results: {result_count}")
        
        print(f"\\n📈 Total: {total_rules} rules, {total_results} findings across {len(sarif['runs'])} tools")
        print("🔗 Features: Fingerprints for deduplication, precision levels, artifact URIs")
        print("📋 Tools: cargo-audit, cargo-deny, cargo-geiger, dependency analysis")
        
        EOF

    # Upload separate SARIF files for better GitHub Security tab organization
    - name: Create individual SARIF files
      run: |
        python3 << 'EOF'
        import json
        
        # Load comprehensive SARIF
        with open('security-results.sarif', 'r') as f:
            sarif = json.load(f)
        
        # Create individual SARIF files per tool for better GitHub integration
        for run in sarif['runs']:
            tool_name = run['tool']['driver']['name']
            filename = f"security-results-{tool_name.replace('-', '_')}.sarif"
            
            individual_sarif = {
                "$schema": sarif["$schema"],
                "version": sarif["version"],
                "runs": [run]
            }
            
            with open(filename, 'w') as f:
                json.dump(individual_sarif, f, indent=2)
            
            print(f"Created {filename} with {len(run.get('results', []))} results")
        EOF

    - name: Upload Audit SARIF
      if: hashFiles('security-results-cargo_audit.sarif') != ''
      uses: github/codeql-action/upload-sarif@v3
      with:
        sarif_file: security-results-cargo_audit.sarif
        category: cargo-audit

    - name: Upload Deny SARIF
      if: hashFiles('security-results-cargo_deny.sarif') != ''
      uses: github/codeql-action/upload-sarif@v3
      with:
        sarif_file: security-results-cargo_deny.sarif
        category: cargo-deny

    - name: Upload Geiger SARIF
      if: hashFiles('security-results-cargo_geiger.sarif') != ''
      uses: github/codeql-action/upload-sarif@v3
      with:
        sarif_file: security-results-cargo_geiger.sarif
        category: cargo-geiger

    - name: Upload Dependency Analysis SARIF
      if: hashFiles('security-results-dnspx_dependency_analyzer.sarif') != ''
      uses: github/codeql-action/upload-sarif@v3
      with:
        sarif_file: security-results-dnspx_dependency_analyzer.sarif
        category: dependency-analysis

  # ===== ARTIFACT CLEANUP =====
  cleanup-old-artifacts:
    name: Cleanup Old Artifacts
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    steps:
    - name: Cleanup old security artifacts
      run: |
        echo "🧹 Cleaning up artifacts older than 14 days..."
        
        # Calculate cutoff date (14 days ago)
        CUTOFF_DATE=$(date -d "14 days ago" --iso-8601)
        echo "Cutoff date: $CUTOFF_DATE"
        
        # List and delete old security-related artifacts
        gh api repos/${{ github.repository }}/actions/artifacts \
          --jq '.artifacts[] | select(.name | test("security-reports-|dependency-reports-|supply-chain-reports-")) | select(.created_at < "'$CUTOFF_DATE'") | .id' \
          | while read artifact_id; do
              echo "Deleting artifact ID: $artifact_id"
              gh api -X DELETE repos/${{ github.repository }}/actions/artifacts/$artifact_id || true
            done
        
        echo "✅ Artifact cleanup completed"
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # ===== COMPREHENSIVE SECURITY SUMMARY =====
  security-summary:
    name: Security Summary
    runs-on: ubuntu-latest
    needs: [vulnerability-scan]
    if: always()
    steps:
    - name: Download all reports
      uses: actions/download-artifact@v4
      with:
        path: reports/

    - name: Generate security summary
      run: |
        echo "# 🔒 Security Audit Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Audit Date:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Vulnerability scan results
        echo "## 🛡️ Vulnerability Scan" >> $GITHUB_STEP_SUMMARY
        if [[ "${{ needs.vulnerability-scan.result }}" == "success" ]]; then
          echo "✅ **Status:** No critical vulnerabilities found" >> $GITHUB_STEP_SUMMARY
        else
          echo "⚠️ **Status:** Issues detected - review required" >> $GITHUB_STEP_SUMMARY
        fi
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Dependency analysis results (conditional based on trigger)
        echo "## 📦 Dependency Analysis" >> $GITHUB_STEP_SUMMARY
        if [[ "${{ github.event_name }}" == "schedule" || "${{ github.event_name }}" == "workflow_dispatch" ]]; then
          # Jobs ran, show actual results (note: we need to handle this differently since needs are not available)
          echo "✅ **Status:** Deep dependency analysis completed" >> $GITHUB_STEP_SUMMARY
          echo "   - Unused dependencies checked (machete, udeps)" >> $GITHUB_STEP_SUMMARY
          echo "   - Outdated dependencies identified" >> $GITHUB_STEP_SUMMARY
        else
          echo "⏭️ **Status:** Skipped (optimization - only runs on schedule/manual)" >> $GITHUB_STEP_SUMMARY
          echo "   - Push events focus on critical vulnerabilities only" >> $GITHUB_STEP_SUMMARY
        fi
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Supply chain results (conditional based on trigger)
        echo "## 🔗 Supply Chain Security" >> $GITHUB_STEP_SUMMARY
        if [[ "${{ github.event_name }}" == "schedule" || "${{ github.event_name }}" == "workflow_dispatch" ]]; then
          echo "✅ **Status:** Supply chain verification completed" >> $GITHUB_STEP_SUMMARY
          echo "   - Cargo-vet audits processed" >> $GITHUB_STEP_SUMMARY
          echo "   - Community reviews checked (if enabled)" >> $GITHUB_STEP_SUMMARY
        else
          echo "⏭️ **Status:** Skipped (optimization - only runs on schedule/manual)" >> $GITHUB_STEP_SUMMARY
          echo "   - Push events focus on critical vulnerabilities only" >> $GITHUB_STEP_SUMMARY
        fi
        echo "" >> $GITHUB_STEP_SUMMARY
        
        echo "## 📊 Reports & Artifacts" >> $GITHUB_STEP_SUMMARY
        echo "- **SARIF Report**: Uploaded to GitHub Security tab (permanent)" >> $GITHUB_STEP_SUMMARY
        if [[ "${{ github.event_name }}" == "workflow_dispatch" || "${{ github.event_name }}" == "schedule" ]]; then
          echo "- **Detailed Reports**: Available as artifacts (7-14 days retention)" >> $GITHUB_STEP_SUMMARY
          echo "  - Security Reports (audit, deny, geiger)" >> $GITHUB_STEP_SUMMARY
          echo "  - Dependency Reports (machete, udeps, outdated)" >> $GITHUB_STEP_SUMMARY
          echo "  - Supply Chain Reports (vet, crev)" >> $GITHUB_STEP_SUMMARY
        else
          echo "- **Detailed Reports**: Artifacts only saved for scheduled/manual runs" >> $GITHUB_STEP_SUMMARY
          echo "  - Push events use SARIF upload only (storage optimized)" >> $GITHUB_STEP_SUMMARY
        fi

    - name: Create issue on security failures
      if: needs.vulnerability-scan.result == 'failure'
      uses: actions/github-script@v7
      with:
        script: |
          const title = `Security Audit Failed - ${new Date().toISOString().split('T')[0]}`;
          const body = `
          ## 🚨 Security Audit Failure
          
          **Date:** ${new Date().toISOString()}
          **Workflow:** ${{ github.workflow }}
          **Run:** ${{ github.run_id }}
          
          ### Results:
          - Vulnerability Scan: ${{ needs.vulnerability-scan.result }}
          - Dependency Analysis: ${{ github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' && 'completed' || 'skipped (push optimization)' }}
          - Supply Chain: ${{ github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' && 'completed' || 'skipped (push optimization)' }}
          
          ### Known Exceptions (SECURITY.md & deny.toml):
          - ✅ RUSTSEC-2023-0071: RSA Marvin Attack (Windows SSPI only)
          - ✅ RUSTSEC-2021-0145: atty unaligned read (inquire dependency)
          - ✅ RUSTSEC-2024-0375: atty unmaintained (inquire dependency)
          - ✅ RUSTSEC-2024-0436: paste crate unmaintained (no alternatives)
          
          ### Action Required:
          1. Review security reports for NEW vulnerabilities (not in exceptions list)
          2. Check if Windows SSPI mitigations are still appropriate
          3. Monitor for paste crate alternatives in ratatui ecosystem
          4. Update SECURITY.md if new advisories need documentation
          5. Consider updating sspi/picky dependencies if available
          
          ### Special Considerations:
          - **Windows Builds**: Monitor for sspi crate updates addressing RUSTSEC-2023-0071
          - **SSPI Usage**: Review production deployments using Windows SSPI auth
          - **Timing Attacks**: Ensure network monitoring is in place for Windows systems
          - **paste crate**: Monitor ratatui issues for paste replacement alternatives
          - **TUI Features**: Consider if TUI functionality can be simplified to reduce dependencies
          
          **Reports:** [View Workflow Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
          **Security Policy:** [SECURITY.md](https://github.com/${{ github.repository }}/blob/main/SECURITY.md)
          `;
          
          // Check if issue already exists
          const issues = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            labels: ['security', 'audit-failure'],
            state: 'open'
          });
          
          if (issues.data.length === 0) {
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: body,
              labels: ['security', 'audit-failure', 'priority-high', 'windows-sspi']
            });
          }
